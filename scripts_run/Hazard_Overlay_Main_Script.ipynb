{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "from Hz_overlay_functions_module import load_region_shapefile, load_networks, filter_network_by_region, create_segments_simple, move_output_file, copy_and_prepare_flood_map\n",
    "from ra2ce.network.network_config_data.network_config_data import NetworkConfigData, NetworkSection, HazardSection\n",
    "from ra2ce.network.network_config_data.enums.source_enum import SourceEnum\n",
    "from ra2ce.network.network_config_data.enums.aggregate_wl_enum import AggregateWlEnum\n",
    "from ra2ce.analysis.damages.damages import AnalysisSectionDamages\n",
    "from ra2ce.analysis.analysis_config_data.enums.analysis_damages_enum import AnalysisDamagesEnum\n",
    "from ra2ce.analysis.analysis_config_data.enums.event_type_enum import EventTypeEnum\n",
    "from ra2ce.analysis.analysis_config_data.enums.damage_curve_enum import DamageCurveEnum\n",
    "from ra2ce.analysis.analysis_config_data.analysis_config_data import AnalysisConfigData\n",
    "from ra2ce.ra2ce_handler import Ra2ceHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756db623",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = [\"Achterhoek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region_shapefile = Path(r\"P:\\bovenregionale-stresstest-hwn\\Data\\Hazard_maps\\Gebiedsindeling obv waterschappen EXPORT 4dec24.gpkg\")\n",
    "HWN_network = Path(r\"P:\\bovenregionale-stresstest-hwn\\Data\\Shapes netwerkschakels\\Shapes netwerkschakels\\HWN_netwerkindeling.shp\")\n",
    "NWB_network = Path(r\"P:\\bovenregionale-stresstest-hwn\\Data\\Road_data\\Rijkswegen_uit_nwb\\rijkswegen.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for region in region_list:\n",
    "    print(f\"Processing region: {region} hazard map\")\n",
    "    flood_map_folder = Path(rf\"P:\\bovenregionale-stresstest-hwn\\Data\\Hazard_maps\\Hazard_maps-in_use\\{region}\\Basisscenario\\waterdiepte\")\n",
    "    flood_map_files = list(flood_map_folder.glob(\"*max_wd_merge_clipNL.tif\")) + list(flood_map_folder.glob(\"*max_wd_merge_clipNL.tiff\"))\n",
    "    flood_duration_folder = Path(rf\"P:\\bovenregionale-stresstest-hwn\\Data\\Hazard_maps\\Hazard_maps-in_use\\{region}\\Basisscenario\\Duur\")\n",
    "    Flood_duration_files = list(flood_duration_folder.glob(\"*duur_merge.tif\")) + list(flood_map_folder.glob(\"*duur_merge.tiff\"))\n",
    "    \n",
    "    if flood_map_files:\n",
    "        flood_map_path = flood_map_files[0]\n",
    "        print(f\"Using flood map: {flood_map_path}\")\n",
    "    else:\n",
    "        print(\"No TIFF files found in the folder.\")\n",
    "        \n",
    "    if Flood_duration_files:\n",
    "        flood_duration_path = Flood_duration_files[0]\n",
    "        print(f\"Using flood duration map: {flood_duration_path}\")\n",
    "    else:\n",
    "        print(\"No TIFF files found in the folder.\")\n",
    "\n",
    "    print(\"Processing networks - clipping to region and joining HWN and NWB networks\")\n",
    "    region_gdf, filtered_region = load_region_shapefile(region_shapefile, region)\n",
    "    joined_network = load_networks(HWN_network, NWB_network)\n",
    "    \n",
    "    print(joined_network.columns)\n",
    "    code = 'NWSCODE_HWN'  # This is what we use to clip ex: Networkschals inbetween regions should not be clipped\n",
    "    filtered_network_gdf = filter_network_by_region(joined_network, filtered_region,code)\n",
    "    \n",
    "    print(\"Segmenting networks into 100m segments\")\n",
    "    print(\"Here we chose the NWB ID as the metric for segmenting the network into 100m segments.\")\n",
    "    segmentation_metric = 'id_NWB' #determine which metric to use for 100m segments\n",
    "    segmented_gdfs = []\n",
    "    grouped_networks = filtered_network_gdf.groupby(segmentation_metric)\n",
    "\n",
    "    id_counter = 1\n",
    "    for nwscode, group in grouped_networks:\n",
    "        group_segments = []\n",
    "        for idx, row in group.iterrows():\n",
    "            segments_gdf = create_segments_simple(row.geometry, segment_length=100)\n",
    "            for seg_idx, segment_row in segments_gdf.iterrows():\n",
    "                new_row = row.copy()\n",
    "                new_row.geometry = segment_row.geometry\n",
    "                new_row['segment_id'] = f\"{idx}_{seg_idx}\"\n",
    "                new_row['original_id'] = idx\n",
    "                new_row['segment_number'] = seg_idx\n",
    "                new_row['segment_length'] = segment_row.geometry.length\n",
    "                new_row['highway'] = \"motorway\"\n",
    "                new_row['lanes'] = 1\n",
    "                new_row['REF_ID'] = id_counter \n",
    "                id_counter += 1  \n",
    "                \n",
    "                group_segments.append(new_row)\n",
    "        if group_segments:\n",
    "            group_gdf = gpd.GeoDataFrame(group_segments, crs=group.crs)\n",
    "            segmented_gdfs.append(group_gdf)\n",
    "\n",
    "    if segmented_gdfs:\n",
    "        segmented_network_gdf = gpd.pd.concat(segmented_gdfs, ignore_index=True)\n",
    "    else:\n",
    "        segmented_network_gdf = filtered_network_gdf.copy()\n",
    "\n",
    "    print(\"creating inputs for RA2CE run\")\n",
    "    region_dir = Path(rf\"P:\\bovenregionale-stresstest-hwn\\Analysis\\{region}\")\n",
    "    input_dir = region_dir.joinpath(\"Inputs\")\n",
    "    output_path = region_dir.joinpath(\"Outputs\")\n",
    "    static_path = input_dir.joinpath(\"static\")\n",
    "    overlay_path = static_path.joinpath(\"output_graph\")\n",
    "    network_path = static_path.joinpath(\"network\")\n",
    "    hazard_path = static_path.joinpath(\"hazard\")\n",
    "    \n",
    "    \n",
    "\n",
    "    for path in [region_dir, input_dir, static_path, network_path, hazard_path, output_path, output_path]:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    segmented_network_file = network_path.joinpath(f\"{region}_segmented_network.shp\")\n",
    "    columns_to_drop = [col for col in segmented_network_gdf.columns if col.startswith('geometry_') and col != 'geometry']\n",
    "    segmented_network_clean = segmented_network_gdf.drop(columns=columns_to_drop)\n",
    "    segmented_network_clean.to_file(segmented_network_file)\n",
    "\n",
    "    print(\"Preprocessing Flood Map\")\n",
    "    copy_and_prepare_flood_map(flood_map_path, hazard_path, nodata_value=-9999)\n",
    "    copy_and_prepare_flood_map(flood_duration_path, hazard_path, nodata_value=-9999)\n",
    "\n",
    "\n",
    "    root_dir = input_dir\n",
    "    network_section = NetworkSection(\n",
    "        source=SourceEnum.SHAPEFILE,\n",
    "        primary_file=[network_path.joinpath(f\"{region}_segmented_network.shp\")],\n",
    "        file_id=\"REF_ID\",\n",
    "        link_type_column=\"highway\",\n",
    "        save_gpkg=True\n",
    "    )\n",
    "\n",
    "    hazard = HazardSection(\n",
    "        hazard_map=[Path(file) for file in hazard_path.glob(\"*.tif\")],\n",
    "        aggregate_wl=AggregateWlEnum.MAX,\n",
    "        hazard_crs=\"EPSG:28992\"\n",
    "    )\n",
    "\n",
    "    network_config_data = NetworkConfigData(\n",
    "        root_path=root_dir,\n",
    "        static_path=static_path,\n",
    "        output_path=output_path,\n",
    "        network=network_section,\n",
    "        hazard=hazard\n",
    "    )\n",
    "    \n",
    "    section_damage = [AnalysisSectionDamages(\n",
    "    name='HZ_damage',\n",
    "    analysis=AnalysisDamagesEnum.DAMAGES,\n",
    "    event_type=EventTypeEnum.EVENT,\n",
    "    damage_curve=DamageCurveEnum.HZ,\n",
    "    save_gpkg=True,\n",
    "    save_csv=True,\n",
    "    )]\n",
    "    \n",
    "    analysis_config_data = AnalysisConfigData(analyses=section_damage, root_path=root_dir, output_path=output_path)\n",
    "    analysis_config_data.input_path = root_dir.joinpath(\"input_data\")\n",
    "\n",
    "    print(\"Creating RA2CE handler and running analysis\")\n",
    "    handler = Ra2ceHandler.from_config(network_config_data, analysis_config_data)\n",
    "    handler.configure()\n",
    "    handler.run_analysis()\n",
    "\n",
    "    move_output_file(overlay_path, output_path, \"base_network_hazard.gpkg\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
