{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e85050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading traffic centers...\n",
      "Loaded 6 traffic centers with 1000m buffers\n",
      "\n",
      "=== Processing region: ARK-NZK ===\n",
      "Found 1 flood map files for region ARK-NZK\n",
      "Processing ARKNZK-max_wd_merge_clipNL.tif...\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Error processing geometry 5: Input shapes do not overlap raster.\n",
      "\n",
      "=== Processing region: Vallei en Veluwe ===\n",
      "Found 1 flood map files for region Vallei en Veluwe\n",
      "Processing samengevoegd_max_inundatiediepte_5m_max_wd_merge_clipNL.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 4: Input shapes do not overlap raster.\n",
      "Error processing geometry 5: Input shapes do not overlap raster.\n",
      "\n",
      "=== Processing region: Noord-Westelijke Delta ===\n",
      "Found 4 flood map files for region Noord-Westelijke Delta\n",
      "Processing Merge_maxWD_ZH_200mm_Nat.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Processing RMM_merge_max_wd_merge_clipNL.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Error processing geometry 4: Input shapes do not overlap raster.\n",
      "Processing SK2_maxWD_ZH_200mm_Nat.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Error processing geometry 4: Input shapes do not overlap raster.\n",
      "Error processing geometry 5: Input shapes do not overlap raster.\n",
      "Processing SK_maxWD_ZH_200mm_Nat.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 1: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Error processing geometry 4: Input shapes do not overlap raster.\n",
      "Error processing geometry 5: Input shapes do not overlap raster.\n",
      "\n",
      "=== Processing region: Noord-Brabant Oost ===\n",
      "Found 1 flood map files for region Noord-Brabant Oost\n",
      "Processing Basisgebeurtenis_max_wd_merge_clipNL.tif...\n",
      "Error processing geometry 0: Input shapes do not overlap raster.\n",
      "Error processing geometry 2: Input shapes do not overlap raster.\n",
      "Error processing geometry 3: Input shapes do not overlap raster.\n",
      "Error processing geometry 4: Input shapes do not overlap raster.\n",
      "Error processing geometry 5: Input shapes do not overlap raster.\n",
      "Creating summary columns with maximum values across all regions...\n",
      "Summary statistics:\n",
      "  - Traffic centers with flood data: 6\n",
      "  - Traffic centers with flooding (>0m): 6\n",
      "  - Maximum flood depth found: 7.16m\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: table gpkg_extensions already exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mfiona\\_err.pyx:201\u001b[39m, in \u001b[36mfiona._err.GDALErrCtxManager.__exit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m: b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: table gpkg_extensions already exists'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._shim.gdal_flush_cache'\n",
      "Traceback (most recent call last):\n",
      "  File \"fiona\\_err.pyx\", line 201, in fiona._err.GDALErrCtxManager.__exit__\n",
      "fiona._err.CPLE_AppDefinedError: b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: table gpkg_extensions already exists'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to:\n",
      "  - GeoPackage: P:\\bovenregionale-stresstest-hwn\\Analysis\\Traffic_Central_Analysis\\traffic_centers_with_flood_depths.gpkg\n",
      "  - Excel: P:\\bovenregionale-stresstest-hwn\\Analysis\\Traffic_Central_Analysis\\traffic_centers_with_flood_depths.xlsx\n",
      "\n",
      "Analysis complete!\n",
      "Processed 7 flood maps across 4 regions.\n"
     ]
    }
   ],
   "source": [
    "#Traffic Center analysis\n",
    "\n",
    "from post_processing_functions import load_traffic_centers, process_all_regions, save_results\n",
    "\n",
    "def run_flood_analysis():\n",
    "    \n",
    "    # Configuration\n",
    "    traffic_centers_file = r\"P:\\bovenregionale-stresstest-hwn\\Data\\Traffic_centrals\\Traffic_centers.xlsx\"\n",
    "    hazard_maps_base_path = r\"P:\\bovenregionale-stresstest-hwn\\Data\\Hazard_maps\\Hazard_maps-in_use\"\n",
    "    output_directory = r\"P:\\bovenregionale-stresstest-hwn\\Analysis\\Traffic_Central_Analysis\"\n",
    "    region_list = [\"ARK-NZK\", \"Vallei en Veluwe\", \"Noord-Westelijke Delta\", \"Noord-Brabant Oost\"]\n",
    "    buffer_distance = 1000  # meters\n",
    "    \n",
    "    # Step 1: Load and buffer traffic centers\n",
    "    gdf_buffered = load_traffic_centers(traffic_centers_file, buffer_distance)\n",
    "    \n",
    "    # Step 2: Process all regions and flood maps\n",
    "    gdf_with_floods, all_results = process_all_regions(gdf_buffered, region_list, hazard_maps_base_path)\n",
    "    \n",
    "    # Step 3: Save results\n",
    "    gpkg_path, excel_path = save_results(gdf_with_floods, output_directory)\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary_stats = {\n",
    "        'total_traffic_centers': len(gdf_with_floods),\n",
    "        'centers_with_flood_data': (gdf_with_floods['max_flood_depth'] != -9999).sum(),\n",
    "        'centers_with_flooding': (gdf_with_floods['max_flood_depth'] > 0).sum(),\n",
    "        'max_flood_depth_found': gdf_with_floods['max_flood_depth'].max(),\n",
    "        'mean_flood_depth': gdf_with_floods[gdf_with_floods['max_flood_depth'] != -9999]['max_flood_depth'].mean(),\n",
    "        'gpkg_path': gpkg_path,\n",
    "        'excel_path': excel_path\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nAnalysis complete!\")\n",
    "    print(f\"Processed {len(all_results)} flood maps across {len(region_list)} regions.\")\n",
    "    \n",
    "    # Return the three values that the calling code expects\n",
    "    return gdf_with_floods, summary_stats, all_results\n",
    "    \n",
    "gdf_results, summary, results_list = run_flood_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: Vallei en Veluwe network\n",
      "Aggregated network saved to P:\\bovenregionale-stresstest-hwn\\Analysis\\Vallei en Veluwe\\Outputs\\Vallei en Veluwe_aggregated_network_to_NWB.gpkg\n"
     ]
    }
   ],
   "source": [
    "#Network Aggregation\n",
    "from post_processing_functions import aggregate_line_sections\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "#region_list = [\"Friesland\", \"Vallei en Veluwe\"]\n",
    "region_list = [\"Vallei en Veluwe\"]\n",
    "\n",
    "for region in region_list:\n",
    "    print(f\"Processing region: {region} network\")\n",
    "    root_dir = Path(rf\"P:\\bovenregionale-stresstest-hwn\\Analysis\\{region}\\Outputs\")\n",
    "    network_file = root_dir / \"base_network_hazard.gpkg\"\n",
    "    network_gdf = gpd.read_file(network_file)\n",
    "\n",
    "    aggregated = aggregate_line_sections(network_gdf, column='id_NWB', agg_method='mean')\n",
    "    aggregated.to_file(root_dir / f\"{region}_aggregated_network_to_NWB.gpkg\", driver='GPKG')\n",
    "    print(f\"Aggregated network saved to {root_dir / f'{region}_aggregated_network_to_NWB.gpkg'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: Limburg network\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: disk I/O error'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mfiona\\_err.pyx:201\u001b[39m, in \u001b[36mfiona._err.GDALErrCtxManager.__exit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m: b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: disk I/O error'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._shim.gdal_flush_cache'\n",
      "Traceback (most recent call last):\n",
      "  File \"fiona\\_err.pyx\", line 201, in fiona._err.GDALErrCtxManager.__exit__\n",
      "fiona._err.CPLE_AppDefinedError: b'sqlite3_exec(CREATE TABLE gpkg_extensions (table_name TEXT,column_name TEXT,extension_name TEXT NOT NULL,definition TEXT NOT NULL,scope TEXT NOT NULL,CONSTRAINT ge_tce UNIQUE (table_name, column_name, extension_name))) failed: disk I/O error'\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "b\"sqlite3_exec(UPDATE gpkg_contents SET last_change = strftime('%Y-%m-%dT%H:%M:%fZ','now') WHERE lower(table_name) = lower('afr_Points')) failed: unable to open database file\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mfiona\\_err.pyx:201\u001b[39m, in \u001b[36mfiona._err.GDALErrCtxManager.__exit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m: b\"sqlite3_exec(UPDATE gpkg_contents SET last_change = strftime('%Y-%m-%dT%H:%M:%fZ','now') WHERE lower(table_name) = lower('afr_Points')) failed: unable to open database file\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._shim.gdal_flush_cache'\n",
      "Traceback (most recent call last):\n",
      "  File \"fiona\\_err.pyx\", line 201, in fiona._err.GDALErrCtxManager.__exit__\n",
      "fiona._err.CPLE_AppDefinedError: b\"sqlite3_exec(UPDATE gpkg_contents SET last_change = strftime('%Y-%m-%dT%H:%M:%fZ','now') WHERE lower(table_name) = lower('afr_Points')) failed: unable to open database file\"\n"
     ]
    }
   ],
   "source": [
    "#On off ramp analysis\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from post_processing_functions import cluster_connected,aggregate_clusters_to_points\n",
    "#region_list = [\"Friesland\", \"Vallei en Veluwe\",\"Noord-Westelijke Delta\",\"Limburg\"]\n",
    "region_list = [\"Limburg\"]\n",
    "\n",
    "for region in region_list:\n",
    "    print(f\"Processing region: {region} network\")\n",
    "    root_dir = Path(rf\"P:\\bovenregionale-stresstest-hwn\\Analysis\\{region}\\Outputs\")\n",
    "    network_file = root_dir / \"base_network_hazard.gpkg\"\n",
    "    network_gdf = gpd.read_file(network_file)\n",
    "    ramps_gdf = network_gdf[network_gdf[\"BST_CODE_N\"].isin([\"AFR\", \"OPR\"])]\n",
    "    afr_gdf = ramps_gdf[ramps_gdf[\"BST_CODE_N\"] == \"AFR\"].copy()\n",
    "    opr_gdf = ramps_gdf[ramps_gdf[\"BST_CODE_N\"] == \"OPR\"].copy()\n",
    "    \n",
    "    afr_gdf_clustered = cluster_connected(afr_gdf)\n",
    "    output_gpkg = root_dir / \"afr_LineSegments.gpkg\"\n",
    "    afr_gdf_clustered.to_file(output_gpkg, driver=\"GPKG\")\n",
    "\n",
    "    \n",
    "    afr_gdf_aggregated = aggregate_clusters_to_points(afr_gdf_clustered, \"EV1_ma\", method=\"mean\")\n",
    "    output_gpkg_aggregated = root_dir / \"afr_Points.gpkg\"\n",
    "    afr_gdf_aggregated.to_file(output_gpkg_aggregated, driver=\"GPKG\")\n",
    "\n",
    "    opr_gdf_clustered = cluster_connected(opr_gdf)\n",
    "    output_gpkg = root_dir / \"opr_LineSegments.gpkg\"\n",
    "    opr_gdf_clustered.to_file(output_gpkg, driver=\"GPKG\")\n",
    "\n",
    "    opr_gdf_aggregated = aggregate_clusters_to_points(opr_gdf_clustered, \"EV1_ma\", method=\"mean\")\n",
    "    output_gpkg_aggregated = root_dir / \"opr_Points.gpkg\"\n",
    "    opr_gdf_aggregated.to_file(output_gpkg_aggregated, driver=\"GPKG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra2ce_env_brs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
